{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: sep 2022\n",
    "# This script does no longer work correctly on the wikipedia page of the exercise, since it has changed over time\n",
    "# since this script has been developed in 2019\n",
    "# It might nevertheless be useful as a starting point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import urllib\n",
    "import time\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "headers = {'user-agent': 'scrapingCourseBot'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This convenience function finds the text directly inside a BeautifulSoup tag, ignoring any text in descendant tags. It also cleans up the text by stripping leading and trailing whitespace. Such whitespace  is irrelevant in HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_text_only(tag):\n",
    "    text = tag.find(text=True, recursive=False)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First part of the exercise: find country and song name for all songs in the final of the 2018 Eurovision song contest. This data can be found in [https://en.wikipedia.org/wiki/Eurovision_Song_Contest_2018](https://en.wikipedia.org/wiki/Eurovision_Song_Contest_2018). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/Eurovision_Song_Contest_2018\"\n",
    "page = requests.get(url, headers=headers)\n",
    "print(url, page.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This page contains a table with all the data in the section \"Participating Countries\", in the \"Final\" subsection. This subsection can easily be found by its id, which is also \"Final\"; the table is contained in the first &lt;table&gt; HTML element after that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.text, \"lxml\")\n",
    "\n",
    "final = soup.find(id = \"Final\")\n",
    "table = final.findNext(\"table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each column in this table contains a separate variable, while each row in the table represents one song. The first row contains column headers, with citations for each header. We process this table one row at a time, starting with the row with column headers. We extract all column headers, and make sure to get rid of the unwanted citations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each table row is contained in a <tr> tag.\n",
    "rows = table.find_all(\"tr\")\n",
    "\n",
    "# The column headers are inside the first table row, inside <th> tags.\n",
    "firstrow_cells = rows[0].find_all(\"th\")\n",
    "headers = [ find_text_only(cell) for cell in firstrow_cells ]\n",
    "print(headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we extract the variables we want from the remaining rows in the table. For each row, we loop simultaneously through the column headers and the cells in the row, so that we know which variable is contained within each cell. Each cell is contained in a &lt;td&gt; tag.\n",
    "\n",
    "[as a sidenote: I only got the idea of looping through column headers and table cells simultaneously, using zip(), several days after the course had ended. My original solution was quite a bit more complex and therefore much more time-consuming to get right]\n",
    "\n",
    "The question only asked for countries and song names, but we also extract links to individual song pages and the number of points per song, in preparation for the second part of the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for row in rows[1:]:\n",
    "    row_result = {}\n",
    "    row_cells = row.find_all(\"td\")\n",
    "    for header, cell_content in zip(headers, row_cells):\n",
    "        if header == \"Country\":\n",
    "            # We only store the text within the a tag inside the cell,\n",
    "            # because the cell also contains the country flag, which we do not want.\n",
    "            row_result[\"country\"] = cell_content.a.text\n",
    "        elif header == \"Song\":\n",
    "            # Again, we only store the text within the a tag inside the cell,\n",
    "            # this time because the song titles are between quotes, and we do not want those.\n",
    "            row_result[\"songname\"] = cell_content.a.text\n",
    "            # We also store the url to the song page, for future reference.\n",
    "            # We use urllib.parse.urljoin to convert these into absolute urls.\n",
    "            # This is more robust than simply adding \"www.wikipedia.org\" in front.\n",
    "            row_result[\"link\"] = urllib.parse.urljoin(url, cell_content.a[\"href\"])\n",
    "        elif header == \"Points\":\n",
    "            # We only store the text within the cell itself, not its children.\n",
    "            # The reason here is that these cells also contain a hidden tag \n",
    "            # with a sort key, and we do not want those.\n",
    "            # We also convert the result to integer, as we need it as such later.\n",
    "            row_result[\"points\"] = int(find_text_only(cell_content))\n",
    "    results.append(row_result)\n",
    "    print(row_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second part of the exercise: gather release dates, song lengths and songwriters from the\n",
    "individual song pages, for those songs that got at least 100 points.\n",
    "\n",
    "The individual song pages all contain a wikipedia infobox in the sidebar on the right with the required data. The HTML structure of this infobox is the same for all song pages, which makes scraping the required data much simpler. The table itself has the class \"vevent\". Each row is contained in a &lt;tr&gt; tag, and each row contains 1 variable. Within a row, the variable name is contained in a &lt;th&gt; tag, while its value is contained in a &lt;td&gt; tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second part of the exercise: gather release dates, song lengths and songwriters from the\n",
    "# individual song pages, but only for those songs that got at least 100 points\n",
    "for row_result in results:\n",
    "    if row_result[\"points\"] < 100: \n",
    "        continue\n",
    "\n",
    "    # We visist the song's page. We sleep before the request instead of after the request:\n",
    "    # On the one hand, this inserts a pause after the previous page read, and on the other\n",
    "    # hand, this avoids having to wait an extra second after the final request.\n",
    "    time.sleep(1)\n",
    "    page = requests.get(row_result[\"link\"])\n",
    "    print(row_result[\"link\"], page.status_code) # As before, we print a log message\n",
    "    soup = BeautifulSoup(page.text, \"lxml\")\n",
    "\n",
    "    # The data we want is in the table in the sidebar on the right. This table has\n",
    "    # class name \"vevent\".\n",
    "    detail_table = soup.find(\"table\", {\"class\": \"vevent\"})\n",
    "\n",
    "    # This table has a separate variable in each row, with one <th> tag containing\n",
    "    # the variable name, and one <td> tag containing its value.\n",
    "    # We therefore simply loop over all rows\n",
    "    rows = detail_table.find_all(\"tr\")\n",
    "    for row in rows:\n",
    "        label_cell = row.th\n",
    "        value_cell = row.td\n",
    "        if label_cell is not None and value_cell is not None:\n",
    "            label = label_cell.text\n",
    "            if label == \"Released\":\n",
    "                # We use find_text_only() here, because it is more robust\n",
    "                # than simply copying all text. Also, for some songs, the release\n",
    "                # date is accompanied by a wikipedia citation, which we do not want.\n",
    "                row_result[\"released\"] = find_text_only(value_cell)\n",
    "            elif label == \"Length\":\n",
    "                # Most song lengths are strings with format \"min:sec\". One might\n",
    "                # be tempted to parse this string here to store the song length\n",
    "                # as a number of seconds, but we choose not to do so: if\n",
    "                # necessary, we can still do this later.\n",
    "                row_result[\"length\"] = value_cell.text\n",
    "            elif label == \"Songwriter(s)\":\n",
    "                # There may be more than 1 songwriter. For most songs,\n",
    "                # each songwriter is inside a separate <li> tag within\n",
    "                # an <ul> tag. But some songs have a single songwriter \n",
    "                # directly in the cell, without containing <ul> tag\n",
    "                writer_list = value_cell.ul\n",
    "                if writer_list is None:\n",
    "                    # Usually there's a single name here, but there's one\n",
    "                    # case with multiple names separated by commas.\n",
    "                    row_result[\"songwriters\"] = [ name.strip() for name in value_cell.text.split(\",\") ]\n",
    "                else:\n",
    "                    # We use all text inside the <li> tags. We believe \n",
    "                    # that in this case, this is more appropriate.\n",
    "                    # We do not want to ignore the text in descendant tags\n",
    "                    # because if we would do so, we would lose names \n",
    "                    # inside hyperlinks.\n",
    "                    row_result[\"songwriters\"] = [ name.text for name in writer_list.find_all(\"li\") ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in results:\n",
    "    print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
